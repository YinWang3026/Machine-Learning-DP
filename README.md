# Machine-Learning-DP
###Proposal
<p> There are many sign language users in America, however, the amount of population that can understand sign language is scarce. Thus, this has inspired us to design a device that will translate sign language, so that sign language users and non-sign language users can communicate freely, without barriers.
	The setup of the system will consist of a video recording device, an arduino or raspberry pi, and a Gyrfalcon dongle for performing fast mathematical calculations. 
The sign language speaker can wave the signs at the camera. Then, using the embedded chip, the video frames will be parsed and, hopefully, preprocessed. Afterwards, the preprocessed frames/images of the sign language will be passed onto the Gyrfalcon dongle, which contains a neural net for deciphering the sign language image. Finally, the translation is displayed on an LED screen.
<\p>

###Detailed Milestone
Checkpoint 1 2/7/19
	Understand the SDK and perhaps initialize a demo program using the Dongle
Checkpoint 2 2/14/19
	Look into a software CNN for sign language recognition
Checkpoint 3 2/21/19
	Finish a python version for CNN
Checkpoint 4 2/28/19
	Complete the set up physically
Checkpoint 5 3/7/19
	Transfer CNN using the SDK to the setup
Checkpoint 6 3/14/19
	Test the set up
Checkpoint 7 3/21/19
	Debug
Checkpoint 8 3/28/19
	Write up
Checkpoint 9 4/4/19
	Prepare for presentation
Checkpoint 10 4/11/19
Checkpoint 11 4/18/19
Checkpoint 12 4/25/19
Checkpoint 13 5/2/19
Checkpoint 14 5/9/19
Checkpoint 15 5/16/19

###Additional Work
Translate to other languages
Possibly create a mobile app that displays the translations in wanted language
